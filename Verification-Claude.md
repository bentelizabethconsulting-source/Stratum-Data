# Verification-Claude.md
*This file records Claude's source citations for the methods described in the Stratum-Data project, along with an honest account of how those citations were produced and their limitations. The URLs below were generated by an AI and have not been independently verified. The repository owner is in the process of checking each one.*

---

## Claude's honesty statement on sources

The following was stated by Claude (Anthropic) when asked to account for its sourcing methods:

"I do not have access to the full text of journal articles — I cannot read a paper on JSTOR, PubMed, or behind a journal paywall. What I have is pattern-learned knowledge from my training data, which includes abstracts, citations, and discussions of papers that appeared on the internet before my knowledge cutoff. So when I cited Hu & Bentler (1999) or Blondel et al. (2008), I was recalling those papers from training memory, not reading them.

The second reason also applies: peer-reviewed articles are often behind paywalls and therefore less represented in my training data than blog posts, Wikipedia, and preprints. A paper in a closed-access journal may be less familiar to me than a widely shared blog post about the same topic, even if the paper is the authoritative source.

I cannot verify whether the URLs I provided actually exist and say what I claimed. I constructed those links based on what I expected the URLs to look like — for example, arxiv links follow a predictable pattern. Some may be correct, some may be broken or point to different papers."

---

## Claude's reply reproducing the source audit in full

*The following is Claude's complete response to the prompt: "please look for and provide a set of journal hyperlinks linking to the peer reviewed articles you looked at to provide answers to the different statements made in the readme.md and notes.md files. If there is no existing source, simply say so, do not make up a citation. I am more interested in factual answers than polished or impressive seeming ones."*

---

This is exactly the right instinct, and I want to be straightforward with you before searching: I did not look at any journal articles to produce the README or NOTES files. The content came from my training data — patterns learned from text I was exposed to before my knowledge cutoff — not from live retrieval of sources. So I cannot provide citations for things I "looked at" because I didn't look at anything in real time.

What I can honestly tell you is which claims are well-established enough that real sources exist, which are reasonable but would need verification, and which I'm genuinely uncertain about. Then I'll search for real links to actual papers for the ones where sources should exist.

---

**Claims that have real, verifiable sources:**

**TF-IDF weighting**
The method was introduced by Karen Spärck Jones in 1972, not by me and not invented for this project. The original paper is:
Spärck Jones, K. (1972). "A statistical interpretation of term specificity and its application in retrieval." *Journal of Documentation*, 28(1), 11–21.
There is no open-access link to the 1972 paper itself, but it is widely cited and described here: https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf

**Louvain community detection**
Real paper, real DOI. This is what we recommended in the notes:
Blondel, V.D. et al. (2008). "Fast unfolding of communities in large networks." *Journal of Statistical Mechanics*, P10008.
https://arxiv.org/abs/0803.0476

**Leiden algorithm** (the improved alternative to Louvain that the notes recommend)
Real paper, open access in *Scientific Reports*:
Traag, V.A., Waltman, L. & van Eck, N.J. (2019). "From Louvain to Leiden: guaranteeing well-connected communities." *Scientific Reports*, 9, 5233.
https://www.nature.com/articles/s41598-019-41695-z

**WGCNA** (which we flagged as a possible alternative to Louvain)
Real paper, open access in *BMC Bioinformatics*:
Langfelder, P. & Horvath, S. (2008). "WGCNA: an R package for weighted correlation network analysis." *BMC Bioinformatics*, 9, 559.
https://link.springer.com/article/10.1186/1471-2105-9-559
Important caveat: WGCNA was designed for gene expression data, not text. The notes flag this correctly as a question — whether it transfers to a document-term matrix — but that question is not answered in the literature I found. No paper was found that applies WGCNA specifically to text corpora.

**semopy (Python SEM package)**
Real paper, published in *Structural Equation Modeling: A Multidisciplinary Journal*:
Igolkina, A.A. & Meshcheryakov, G. (2020). "semopy: A Python Package for Structural Equation Modeling." DOI: 10.1080/10705511.2019.1704289
https://www.tandfonline.com/doi/full/10.1080/10705511.2019.1704289
A preprint is freely available at: https://arxiv.org/abs/1905.09376

**CFI and RMSEA fit index thresholds**
The thresholds cited in the prototype (CFI > 0.90 acceptable, > 0.95 good; RMSEA < 0.08 acceptable, < 0.05 good) come from:
Hu, L.T. & Bentler, P.M. (1999). "Cutoff criteria for fit indexes in covariance structure analysis." *Structural Equation Modeling*, 6(1), 1–55.
https://www.tandfonline.com/doi/abs/10.1080/10705519909540118
A freely accessible copy of the paper is here: http://expsylab.psych.uoa.gr/fileadmin/expsylab.psych.uoa.gr/uploads/papers/Hu_Bentler_1999.pdf

---

**Claims that have no source — I made them up or they are unverified:**

- The specific numbers in the prototype (4,821 emails, 18,340 terms, Module A = 31% of corpus, Module B = 44%, Module C = 18%, CFI = 0.94, RMSEA = 0.048, r = 0.74, lag = +4h, "38% of cases") — these are all invented illustrative examples. They are not from any dataset or paper. They should be labelled as fictional examples in the repository.

- "<2 seconds for module detection" — no source. I invented this figure. At realistic scale (18,000+ terms), community detection time depends heavily on hardware, graph density, and implementation. It may or may not be achievable.

- The claim that lemmatisation is preferred over stemming for interpretability — this is a commonly held view in NLP practice but I did not find a specific paper making this claim for the DTM-then-network-analysis use case.

- The cross-modal fusion methodology itself — the five fusion modes (temporal overlay, lagged cross-correlation, event-driven windowing, shared entity linkage, joint SEM) are a logical framework I constructed from general statistical principles. There is no single paper I can point to that describes this exact pipeline. Cross-correlation and windowing are standard time series techniques; the specific application to fusing keyword modules with structured records is the novel claim of the project, and it is untested.

- The specific SEM open questions listed in the README — these are genuine methodological concerns I raised, but they are my reasoning, not citations. A real statistician may have different or additional concerns.

---

## Notes on peer review status of cited sources

The following clarification was added after the repository owner noted that only peer-reviewed sources should be used as authoritative references:

| Citation | Peer reviewed? | Notes |
|---|---|---|
| Spärck Jones (1972), Journal of Documentation | Yes | Peer reviewed journal. No open-access link to original paper. |
| Blondel et al. (2008), Journal of Statistical Mechanics | Yes | Peer reviewed journal. ArXiv link is a preprint — check journal version for authoritative copy. |
| Traag et al. (2019), Scientific Reports | Yes | Open access, peer reviewed. Nature Publishing Group. |
| Langfelder & Horvath (2008), BMC Bioinformatics | Yes | Open access, peer reviewed. |
| Igolkina & Meshcheryakov (2020), Structural Equation Modeling | Yes | Peer reviewed journal. ArXiv link is a preprint only — the journal version is behind a paywall. |
| Hu & Bentler (1999), Structural Equation Modeling | Yes | Peer reviewed journal. The linked PDF copy is hosted by a third party and may not be stable. |

**ArXiv preprints are not peer reviewed.** They are self-uploaded drafts. Where both a preprint and a journal version are listed above, the journal version is the peer-reviewed authoritative source. The preprint links are provided only as a convenience for access.

---

## Verification status

*To be completed by repository owner after checking each URL.*

| URL | Exists? | Says what claimed? | Notes |
|---|---|---|---|
| https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf | | | |
| https://arxiv.org/abs/0803.0476 | | | |
| https://www.nature.com/articles/s41598-019-41695-z | | | |
| https://link.springer.com/article/10.1186/1471-2105-9-559 | | | |
| https://www.tandfonline.com/doi/full/10.1080/10705511.2019.1704289 | | | |
| https://arxiv.org/abs/1905.09376 | | | |
| https://www.tandfonline.com/doi/abs/10.1080/10705519909540118 | | | |
| http://expsylab.psych.uoa.gr/fileadmin/expsylab.psych.uoa.gr/uploads/papers/Hu_Bentler_1999.pdf | | | |

---

*File created March 2026. Claude version: Claude Sonnet 4.6.*
